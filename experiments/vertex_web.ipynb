{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209363f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-cloud-aiplatform google-auth pydantic python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f929fa45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Iterator, List, Union, Dict, Any, Optional\n",
    "import base64\n",
    "import re\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Google Auth\n",
    "from google.oauth2 import service_account\n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "# Google Vertex SDK deps\n",
    "import vertexai\n",
    "from vertexai.generative_models import (\n",
    "    Content,\n",
    "    GenerativeModel,\n",
    "    GenerationResponse,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    "    Part,\n",
    "    Image,\n",
    ")\n",
    "from vertexai.preview.generative_models import Tool, grounding, GenerationConfig\n",
    "\n",
    "# Google GenAI SDK deps\n",
    "from google import genai\n",
    "from google.genai.types import (\n",
    "    GenerateContentConfig,\n",
    "    GoogleSearch,\n",
    "    HttpOptions,\n",
    "    Tool,\n",
    ")\n",
    "\n",
    "# local env mgmt, don't use in production\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT_JSON = os.getenv(\"VERTEX_API_KEY_JSON\", \"\")\n",
    "\n",
    "SERVICE_ACCOUNT_JSON = SERVICE_ACCOUNT_JSON.strip().replace(\"\\r\", \"\\\\r\") \\\n",
    "                                         .replace(\"\\n\", \"\\\\n\")\n",
    "\n",
    "key_info = json.loads(SERVICE_ACCOUNT_JSON)\n",
    "\n",
    "creds = Credentials.from_service_account_info(\n",
    "    key_info, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5aa09d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlet:__main__\n",
      "New assistant message: \n",
      "The most recent Google Gemini models are:\n",
      "\n",
      "*   **Gemini 2.5 Pro Preview:** Launched on May 6, 2025, this model is Google's most advanced for complex tasks, leading on benchmarks for reasoning and code capabilities [[googleblog.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGUctdDzP874B2d0C4Dyk9FPuNk1eQbiBScnM74AXL2A746ZU-H194Q5QajpA80KFinvOvFoo5a-Wl8ge-yw98KtB1-3iIsQ61JxwDu5hfMFAn8p5IdjjtEOM-RMSuHPMC5iKh9YjNlPb15gwNdXJYJXVhJrgMwbgD_NNo_RCQ=) ğŸ”—, [blog.google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHir41lrwj6I3mjn097743bI73wUpjsTGKcLEnOVmyneN1AF_ftUxdHGRY-gXsg-Emm7NTCAbEHTc0k-3fqiIEJaOpbq9Ag39KPPbk6esONB87TnP3Mp065mb2KuqD7sj1AjBeBE12quFLA571PbfxRyUfHGd8775f9qkP25Da9QzG2-nb_5aX2QZyG1xoU-ifNMw==) ğŸ”—]. It is available in Google AI Studio and the Gemini app for Gemini Advanced users [[blog.google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHir41lrwj6I3mjn097743bI73wUpjsTGKcLEnOVmyneN1AF_ftUxdHGRY-gXsg-Emm7NTCAbEHTc0k-3fqiIEJaOpbq9Ag39KPPbk6esONB87TnP3Mp065mb2KuqD7sj1AjBeBE12quFLA571PbfxRyUfHGd8775f9qkP25Da9QzG2-nb_5aX2QZyG1xoU-ifNMw==) ğŸ”—].\n",
      "*   **Gemini 2.5 Flash:** Launched on April 17, 2025, this model is a fast and efficient \"thinking model\" that provides strong performance [[googleblog.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGUctdDzP874B2d0C4Dyk9FPuNk1eQbiBScnM74AXL2A746ZU-H194Q5QajpA80KFinvOvFoo5a-Wl8ge-yw98KtB1-3iIsQ61JxwDu5hfMFAn8p5IdjjtEOM-RMSuHPMC5iKh9YjNlPb15gwNdXJYJXVhJrgMwbgD_NNo_RCQ=) ğŸ”—, [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGQpWLV6la-ZLadAOlc3eUDFi_F4AJpY_KgmV6n7otAD9r5-fFdOearMGfA6Fp_wO3_-DAtX2mTkJY_5Z2kqgWeO7MiAHUiGbCCtVHPtePCawEmtrkVDOs26bdv) ğŸ”—].\n",
      "\n",
      "Google also recently launched two new models in the Gemini family [[googleblog.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGUctdDzP874B2d0C4Dyk9FPuNk1eQbiBScnM74AXL2A746ZU-H194Q5QajpA80KFinvOvFoo5a-Wl8ge-yw98KtB1-3iIsQ61JxwDu5hfMFAn8p5IdjjtEOM-RMSuHPMC5iKh9YjNlPb15gwNdXJYJXVhJrgMwbgD_NNo_RCQ=) ğŸ”—]:\n",
      "\n",
      "*   **Gemini 2.5 Pro Preview (05/06)**\n",
      "*   **Gemini 2.5 Flash (04/17)**\n",
      "\n",
      "These models mark a major leap in video understanding [[googleblog.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGUctdDzP874B2d0C4Dyk9FPuNk1eQbiBScnM74AXL2A746ZU-H194Q5QajpA80KFinvOvFoo5a-Wl8ge-yw98KtB1-3iIsQ61JxwDu5hfMFAn8p5IdjjtEOM-RMSuHPMC5iKh9YjNlPb15gwNdXJYJXVhJrgMwbgD_NNo_RCQ=) ğŸ”—].\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sources:\n",
      "- 1. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGQpWLV6la-ZLadAOlc3eUDFi_F4AJpY_KgmV6n7otAD9r5-fFdOearMGfA6Fp_wO3_-DAtX2mTkJY_5Z2kqgWeO7MiAHUiGbCCtVHPtePCawEmtrkVDOs26bdv) ğŸ”—\n",
      "- 2. [googleblog.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGUctdDzP874B2d0C4Dyk9FPuNk1eQbiBScnM74AXL2A746ZU-H194Q5QajpA80KFinvOvFoo5a-Wl8ge-yw98KtB1-3iIsQ61JxwDu5hfMFAn8p5IdjjtEOM-RMSuHPMC5iKh9YjNlPb15gwNdXJYJXVhJrgMwbgD_NNo_RCQ=) ğŸ”—\n",
      "- 3. [blog.google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHir41lrwj6I3mjn097743bI73wUpjsTGKcLEnOVmyneN1AF_ftUxdHGRY-gXsg-Emm7NTCAbEHTc0k-3fqiIEJaOpbq9Ag39KPPbk6esONB87TnP3Mp065mb2KuqD7sj1AjBeBE12quFLA571PbfxRyUfHGd8775f9qkP25Da9QzG2-nb_5aX2QZyG1xoU-ifNMw==) ğŸ”—\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_content_from_message(message: dict) -> Optional[str]:\n",
    "    if isinstance(message[\"content\"], list):\n",
    "        for item in message[\"content\"]:\n",
    "            if item[\"type\"] == \"text\":\n",
    "                return item[\"text\"]\n",
    "    else:\n",
    "        return message[\"content\"]\n",
    "    return None\n",
    "\n",
    "def get_last_assistant_message(messages: list[dict]) -> Optional[str]:\n",
    "    for message in reversed(messages):\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            return get_content_from_message(message)\n",
    "    return None\n",
    "\n",
    "\n",
    "def outlet(body: dict, user: Optional[dict] = None) -> dict:\n",
    "    print(f\"outlet:{__name__}\")\n",
    "\n",
    "    messages = body[\"messages\"]\n",
    "    assistant_message = get_last_assistant_message(messages)\n",
    "    \n",
    "    # print(f\"Current msg: \\n{assistant_message}\")\n",
    "\n",
    "    if \"<ws_text>\" in assistant_message:\n",
    "        # Translate assistant message\n",
    "        pattern = re.compile(\n",
    "                r\"<ws_text>(?P<text>.*?)<ws_url>(?P<url>.*?)</ws_url></ws_text>\",\n",
    "                re.DOTALL\n",
    "            )\n",
    "        \n",
    "        pairs = [(m.group(\"text\"), m.group(\"url\")) for m in pattern.finditer(assistant_message)]\n",
    "        # print(f\"pairs is {pairs}\")\n",
    "        \n",
    "        new_assistant_message = pattern.sub('', assistant_message)\n",
    "        \n",
    "        sources = set()\n",
    "        for text, url in pairs:\n",
    "            new_assistant_message = new_assistant_message.replace(text, f\"{text} [{url}]\")\n",
    "            urls = url.split(\", \")\n",
    "            for url in urls:\n",
    "                sources.add(url)\n",
    "        \n",
    "        new_assistant_message += f\"\\nSources:\\n\"\n",
    "        for i, url in enumerate(sources):\n",
    "            new_assistant_message += f\"- {i+1}. {url}\\n\"\n",
    "        \n",
    "        print(f\"New assistant message: \\n{new_assistant_message}\")\n",
    "    \n",
    "    assistant_message = new_assistant_message\n",
    "\n",
    "    for message in reversed(messages):\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            message[\"content\"] = assistant_message\n",
    "            break\n",
    "\n",
    "    body = {**body, \"messages\": messages}\n",
    "    return body\n",
    "\n",
    "# 4. Initialize the GenAI client with explicit credentials\n",
    "client = genai.Client(\n",
    "    vertexai=True,\n",
    "    project=\"tts-datagov\",\n",
    "    location=\"us-central1\",\n",
    "    credentials=creds,\n",
    "    http_options=HttpOptions(api_version=\"v1\"),\n",
    ")\n",
    "\n",
    "# 5. Use it exactly as before\n",
    "response_text = \"\"\n",
    "for chunk in client.models.generate_content_stream(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    contents=\"What is the most recent google gemini model?\",\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[\n",
    "            Tool(google_search=GoogleSearch()),  # Use Google Search Tool\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "        top_p=1.0\n",
    "    ),\n",
    "):\n",
    "    urls = []\n",
    "    text_index_pairs = []\n",
    "    # print(chunk, end=\"\")\n",
    "    for candidate in chunk.candidates:\n",
    "        print(chunk.text)\n",
    "        # print(\"\\n====\\n\")\n",
    "        if candidate.grounding_metadata:\n",
    "            if candidate.grounding_metadata.grounding_chunks:\n",
    "                for i, grounding_chunk in enumerate(candidate.grounding_metadata.grounding_chunks):\n",
    "                    web_uri = f\"{grounding_chunk.web.uri}\"\n",
    "                    domain = f\"{grounding_chunk.web.domain}\"\n",
    "                    markdown_link =f\"[{domain}]({web_uri}) ğŸ”—\"\n",
    "                    # print(f\"Grounding metadata index: {i}\")\n",
    "                    # print(f\"{markdown_link}\")\n",
    "                    # print(\"\\n====\\n\")\n",
    "                    urls.append(markdown_link)\n",
    "            if candidate.grounding_metadata.grounding_supports:\n",
    "                for i, grounding_support in enumerate(candidate.grounding_metadata.grounding_supports):\n",
    "                    # print(f\"Grounding support index: {i}\")\n",
    "                    # print(f\"Grounding support: {grounding_support.segment.text}\")\n",
    "                    # print(f\"Indices: {grounding_support.grounding_chunk_indices}\")\n",
    "                    # print(\"\\n====\\n\")\n",
    "                    text_index_pairs.append([grounding_support.segment.text, grounding_support.grounding_chunk_indices])\n",
    "        # print(\"\\n====\\n\")\n",
    "    \n",
    "    response_text += chunk.text\n",
    "    \n",
    "    if text_index_pairs:\n",
    "        for text, indices in text_index_pairs:\n",
    "            md_links = \"\"\n",
    "            for index in indices:\n",
    "                if index < len(urls):\n",
    "                    url = urls[index]\n",
    "                    md_links += f\", {url}\" if md_links else f\"{url}\"\n",
    "            citation = f\"\\n<ws_text>{text}<ws_url>{md_links}</ws_url></ws_text>\"\n",
    "            response_text += citation\n",
    "            # print(f\"citation: {citation}\")\n",
    "            # print(\"\\n====\\n\")\n",
    "\n",
    "        \n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "new_body = outlet(body={\"messages\": [{\"role\": \"assistant\", \"content\": response_text}]})\n",
    "# print(new_body['messages'][0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e240909",
   "metadata": {},
   "source": [
    "As of May 10, 2025, the most recent Google Gemini models are:\n",
    "\n",
    "*   **Gemini 2.5 Pro Preview:** This model is described as Google's most advanced model for complex tasks, leading on benchmarks for reasoning and code capabilities [[blog.google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFb-r7nVjicBd8cNzKz2qhdjyvppxvm2h9uAZO9To-PutW01bZI41uCYWLkcn-tytPthuZirOTDcjVQHAnYVujnKd_VFMbE3f1YW454-RZfqxm-TrT8J-QB_Bf8erTG4s_6kKLhGaAhC5eB2AD8JFuTthqtT-UKQCmAo3yZ0UpsDJZ90i1W6NaxsauwTxpDd-1YxfM=) ğŸ”—, [google.dev](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEkHJQG-bGilRq9-94akRz4lzd_jz9Fx_tMR3MnAI4Xz8LUGsdvWK2I0-O5B8ppOI35DF36IdQxKsvIcnNqS644uWW5L65ukjL87AsCLciqpEZSAvtmzZ8nUeU1wMkCc2mPrhcNqX_M) ğŸ”—]. It is available in Google AI Studio and the Gemini app for Gemini Advanced users [[blog.google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFb-r7nVjicBd8cNzKz2qhdjyvppxvm2h9uAZO9To-PutW01bZI41uCYWLkcn-tytPthuZirOTDcjVQHAnYVujnKd_VFMbE3f1YW454-RZfqxm-TrT8J-QB_Bf8erTG4s_6kKLhGaAhC5eB2AD8JFuTthqtT-UKQCmAo3yZ0UpsDJZ90i1W6NaxsauwTxpDd-1YxfM=) ğŸ”—].\n",
    "*   **Gemini 2.5 Flash:** This model is a highly competitive alternative for cost-sensitive applications [[googleblog.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHnPBbDVOfBxAYtOXyboxZKYDfuOMegOurRp8qL71eQ_gOero2T_4jyiszX1zIqybnFVXK9YHG3D3Cm4vFNTQJ9wPHt66zu-JkfMWtXnr-0C7sT1l59rdq6hZOrBb77usqA4BI0S3fm5f7S7muV8b5b2IN380KOuubAqirG8Dha) ğŸ”—].\n",
    "*   **Gemini 2.0 Flash:** This model is designed for fast responses and strong performance in tasks like brainstorming, learning, and writing [[google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXF2cVnvym1Y5LaF_mL2xKzCmcFFpQl1z5PiWvCwBU-ZdBlfs1Q5AlJDeq5ZD9-arLbNRWjJUN6aKi-pumnI6dCeCdnGiLX8KfTcD_6Rt-gJAxZHvqCWXgSCK5UVwg==) ğŸ”—]. An enhanced version with a more natural conversational style was released on April 19, 2025 [[google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXF2cVnvym1Y5LaF_mL2xKzCmcFFpQl1z5PiWvCwBU-ZdBlfs1Q5AlJDeq5ZD9-arLbNRWjJUN6aKi-pumnI6dCeCdnGiLX8KfTcD_6Rt-gJAxZHvqCWXgSCK5UVwg==) ğŸ”—].\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Sources:\n",
    "- 1. [googleblog.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXHnPBbDVOfBxAYtOXyboxZKYDfuOMegOurRp8qL71eQ_gOero2T_4jyiszX1zIqybnFVXK9YHG3D3Cm4vFNTQJ9wPHt66zu-JkfMWtXnr-0C7sT1l59rdq6hZOrBb77usqA4BI0S3fm5f7S7muV8b5b2IN380KOuubAqirG8Dha) ğŸ”—\n",
    "- 2. [blog.google](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFb-r7nVjicBd8cNzKz2qhdjyvppxvm2h9uAZO9To-PutW01bZI41uCYWLkcn-tytPthuZirOTDcjVQHAnYVujnKd_VFMbE3f1YW454-RZfqxm-TrT8J-QB_Bf8erTG4s_6kKLhGaAhC5eB2AD8JFuTthqtT-UKQCmAo3yZ0UpsDJZ90i1W6NaxsauwTxpDd-1YxfM=) ğŸ”—\n",
    "- 3. [google.dev](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEkHJQG-bGilRq9-94akRz4lzd_jz9Fx_tMR3MnAI4Xz8LUGsdvWK2I0-O5B8ppOI35DF36IdQxKsvIcnNqS644uWW5L65ukjL87AsCLciqpEZSAvtmzZ8nUeU1wMkCc2mPrhcNqX_M) ğŸ”—\n",
    "- 4. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXF2cVnvym1Y5LaF_mL2xKzCmcFFpQl1z5PiWvCwBU-ZdBlfs1Q5AlJDeq5ZD9-arLbNRWjJUN6aKi-pumnI6dCeCdnGiLX8KfTcD_6Rt-gJAxZHvqCWXgSCK5UVwg==) ğŸ”—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bf3ad3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
